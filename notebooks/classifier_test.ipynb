{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\r\n",
      "  Downloading torch-2.4.0-cp39-none-macosx_11_0_arm64.whl (62.1 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m62.1/62.1 MB\u001B[0m \u001B[31m47.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: jinja2 in /Users/cjwang/opt/anaconda3/lib/python3.9/site-packages (from torch) (2.11.3)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/cjwang/opt/anaconda3/lib/python3.9/site-packages (from torch) (4.9.0)\r\n",
      "Requirement already satisfied: filelock in /Users/cjwang/opt/anaconda3/lib/python3.9/site-packages (from torch) (3.6.0)\r\n",
      "Requirement already satisfied: fsspec in /Users/cjwang/opt/anaconda3/lib/python3.9/site-packages (from torch) (2024.6.1)\r\n",
      "Requirement already satisfied: networkx in /Users/cjwang/opt/anaconda3/lib/python3.9/site-packages (from torch) (2.8.4)\r\n",
      "Requirement already satisfied: sympy in /Users/cjwang/opt/anaconda3/lib/python3.9/site-packages (from torch) (1.10.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/cjwang/opt/anaconda3/lib/python3.9/site-packages (from jinja2->torch) (2.0.1)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/cjwang/opt/anaconda3/lib/python3.9/site-packages (from sympy->torch) (1.2.1)\r\n",
      "Installing collected packages: torch\r\n",
      "Successfully installed torch-2.4.0\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install torch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 1.5931\n",
      "Validation Loss: 1.5857\n",
      "Epoch [2/50], Loss: 1.5627\n",
      "Validation Loss: 1.5683\n",
      "Epoch [3/50], Loss: 1.5313\n",
      "Validation Loss: 1.5370\n",
      "Epoch [4/50], Loss: 1.4804\n",
      "Validation Loss: 1.4830\n",
      "Epoch [5/50], Loss: 1.3993\n",
      "Validation Loss: 1.4150\n",
      "Epoch [6/50], Loss: 1.3122\n",
      "Validation Loss: 1.3560\n",
      "Epoch [7/50], Loss: 1.2448\n",
      "Validation Loss: 1.3206\n",
      "Epoch [8/50], Loss: 1.1996\n",
      "Validation Loss: 1.3027\n",
      "Epoch [9/50], Loss: 1.1665\n",
      "Validation Loss: 1.2929\n",
      "Epoch [10/50], Loss: 1.1447\n",
      "Validation Loss: 1.2906\n",
      "Epoch [11/50], Loss: 1.1220\n",
      "Validation Loss: 1.2865\n",
      "Epoch [12/50], Loss: 1.1023\n",
      "Validation Loss: 1.2848\n",
      "Epoch [13/50], Loss: 1.0877\n",
      "Validation Loss: 1.2913\n",
      "Epoch [14/50], Loss: 1.0706\n",
      "Validation Loss: 1.2850\n",
      "Epoch [15/50], Loss: 1.0580\n",
      "Validation Loss: 1.2944\n",
      "Early stopping on epoch 15\n",
      "Accuracy on the test set: 42.00%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Create a simple sample dataset\n",
    "np.random.seed(42)  # For reproducibility\n",
    "\n",
    "num_samples = 1000\n",
    "num_features = 20\n",
    "num_classes = 5\n",
    "\n",
    "# Generate random data\n",
    "X = np.random.randn(num_samples, num_features)\n",
    "# Generate random labels from 0 to 4 (5 classes)\n",
    "y = np.random.randint(0, num_classes, num_samples)\n",
    "\n",
    "# Alternate y so the result can easily be verified.\n",
    "mask = X[:, 0] > 1\n",
    "y[mask] = 1\n",
    "y[~mask] = np.where(y[~mask] == 1, 0, y[~mask])\n",
    "\n",
    "\n",
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create datasets and loaders\n",
    "train_dataset = SimpleDataset(X_train, y_train)\n",
    "test_dataset = SimpleDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define the neural network\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "input_dim = num_features\n",
    "num_classes = num_classes\n",
    "\n",
    "model = SimpleNN(input_dim=input_dim, num_classes=num_classes)\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Early stopping parameters\n",
    "patience = 3\n",
    "best_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "# Training loop with early stopping\n",
    "def train_model(model, train_loader, test_loader, criterion, optimizer, num_epochs=50):\n",
    "    global best_loss, patience_counter\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        running_loss /= len(train_loader)\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss:.4f}')\n",
    "\n",
    "        # Validation loss for early stopping\n",
    "        val_loss = validate_model(model, test_loader)\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(f'Early stopping on epoch {epoch + 1}')\n",
    "            break\n",
    "\n",
    "# Validation function\n",
    "def validate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    val_loss /= len(test_loader)\n",
    "    print(f'Validation Loss: {val_loss:.4f}')\n",
    "    return val_loss\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, test_loader, criterion, optimizer, num_epochs=50)\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy on the test set: {accuracy:.2f}%')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 2.11578471,  0.02462599, -1.17783636, -0.42474439,  0.90291655,\n        -1.02912968, -0.50431203,  0.07163128,  0.2468869 , -0.49929059,\n         0.78686007,  0.5904523 ,  1.1398566 , -0.08160192, -0.51281881,\n        -0.68263202,  0.30702752, -0.37715578, -0.56916978, -0.44828726],\n       [ 1.68369049,  0.19902111, -1.41258318,  0.30301629,  0.67654876,\n        -0.58087914,  1.92203694,  0.01762131, -1.56134298, -0.28124291,\n         0.06265614,  0.44896756, -0.25743052, -1.01157028, -1.09498062,\n        -0.65359929, -0.55777536, -1.13497416, -0.73281316,  0.65945852],\n       [ 2.64841261,  0.75546171,  1.30586109,  0.97411847,  0.83313033,\n        -0.33779626,  0.14091088, -0.42061934, -0.21910716,  0.0681671 ,\n         0.71356615,  0.42332338, -0.16182926,  0.05553874,  0.43346367,\n         0.66739444, -1.51899516, -1.07738896,  1.10731053, -0.06086957],\n       [ 1.42407659, -0.26349947, -0.26370531,  0.55793778, -1.10801639,\n         0.02477775,  0.24611773,  0.39626792,  0.222864  ,  0.51590623,\n        -0.57269615, -0.94180273,  2.45700444, -0.30126468, -0.18445447,\n         0.6778401 ,  1.59608929, -0.54452812, -0.99881527, -1.24215335],\n       [ 2.59310622, -1.03810699, -0.02755594, -0.97728483, -1.44835592,\n        -0.29237535, -0.93778667, -0.69162843,  2.0061051 ,  0.4248961 ,\n         0.93146952,  0.82465956, -0.10086092, -0.43971836,  0.24893461,\n         0.16845077, -0.56880542,  0.12984783, -0.70632971, -0.17145793],\n       [ 1.33528347, -1.26887259, -2.35115821, -0.93906325,  1.80410466,\n        -0.30968178,  0.77596816, -2.12444514, -1.00828607, -1.35448962,\n        -0.20230001,  2.42195548,  0.46023894,  1.69561253, -0.25443673,\n         1.36486937,  2.07325671, -0.10936907, -0.53926471, -1.31781094],\n       [ 1.30906026,  0.08189668,  2.03095362, -1.29497397,  0.05966189,\n        -1.81430812, -0.42676283,  0.31139536,  0.51258315,  0.58902308,\n         0.39740403,  0.58042194,  0.04573913, -1.04786631, -1.85165696,\n        -0.54668782, -0.13461543,  1.2539318 , -0.10060168, -0.19656903],\n       [ 1.38552713, -0.27001199,  0.810542  ,  1.97933362,  2.19078551,\n         0.09704063,  0.33689236,  1.57885612, -0.14996202,  0.67919214,\n        -1.13516013, -0.31083915,  1.15611462, -0.71819563, -0.12805118,\n        -1.57420965,  2.00576829,  1.26302807,  0.18809957,  0.50751287],\n       [ 1.39589811,  1.38431175, -0.51880004,  0.73226762,  1.0774165 ,\n         1.21532597, -2.25937088, -0.59927448, -1.01917062,  0.14958829,\n        -2.01603022, -2.04562289,  2.17009499,  0.61768939,  0.12100924,\n         0.36367265,  0.14634092,  0.99735066, -0.63244419,  0.18661483],\n       [ 1.22742127, -1.04685796,  1.27698306, -0.44567674,  1.01742167,\n         0.11491273,  1.63358483, -1.04137909, -1.0847588 , -0.90569559,\n         0.13329555,  1.5414684 ,  1.59309362, -2.3099686 ,  0.24970716,\n        -3.21295361,  0.79503179,  1.11816941, -0.04024427,  0.08398158]])"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_one = np.random.randn(10, num_features)\n",
    "\n",
    "class_one[:,0] = np.abs(class_one[:,0]) + 1\n",
    "class_one"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 7.36388929e-02, -7.84441919e-01,  4.31705785e-01,\n        -2.31408002e-01,  9.30291709e-01, -1.13626935e-01,\n        -8.61023106e-01, -1.53586467e+00, -1.86406483e+00,\n         1.31250934e+00, -4.57789353e-01,  3.38574190e-01,\n         1.78322989e+00, -5.62804331e-01, -6.27477484e-01,\n        -1.32161752e-01,  2.94327004e-02,  1.88755135e+00,\n         1.56582059e+00,  6.20875416e-01],\n       [ 1.44941377e+00, -1.78219013e-01,  2.99164567e-01,\n        -3.01513645e-01, -1.29036838e+00,  1.20387474e+00,\n         5.31698734e-01,  1.80734734e-02, -2.46784931e-03,\n        -1.50621487e+00, -9.77475333e-01,  3.36153170e-01,\n        -5.29112667e-01, -2.17713041e-01, -1.04656065e-01,\n        -6.82468769e-01, -9.67918320e-01, -1.61235763e+00,\n        -1.46518279e-01,  6.18608548e-01],\n       [-1.64363414e+00, -2.40478251e-02,  2.81143253e-01,\n        -9.89580404e-01,  1.42214181e+00, -3.85715369e-01,\n        -1.01259688e-01, -1.61269501e-01, -1.77077442e+00,\n         1.00875207e+00, -9.55518768e-01, -2.36520515e-01,\n         5.97661001e-01,  1.46090343e+00, -1.07993228e+00,\n        -4.46483586e-01,  1.38241863e+00,  4.63713879e-01,\n         6.71171359e-01, -1.05113174e+00],\n       [-3.79209530e-01, -1.67835432e-01, -8.57894757e-01,\n        -1.67456963e+00, -5.10498559e-01,  1.35428820e+00,\n         5.91734656e-02,  1.37429091e+00,  1.79020914e-01,\n        -7.64707730e-01,  1.27761901e+00,  2.12326141e-01,\n         9.61838832e-01, -1.06832817e+00,  1.03875629e+00,\n         1.06888928e+00,  2.89767144e-01, -8.06922086e-01,\n        -4.60088287e-02,  6.11291147e-01],\n       [ 2.34570020e-01,  6.01082738e-01,  1.01224591e+00,\n        -6.48446653e-01, -1.15507562e+00, -3.75388014e-02,\n        -3.29743159e-01,  7.85846413e-01, -1.07449839e+00,\n         1.02038187e+00,  1.35361211e+00,  3.04964262e-04,\n         6.07361256e-02, -7.67546501e-01, -5.42660899e-01,\n        -4.08336681e-01,  1.44294007e+00, -7.18707858e-02,\n        -1.32217296e+00,  2.55354342e-01],\n       [ 8.26290125e-01, -2.54113693e-02,  1.46921344e+00,\n         7.77508667e-01, -1.04912873e+00, -5.51432812e-01,\n         2.26226281e-01, -1.66618924e+00,  3.36356737e-01,\n        -1.76158243e+00,  1.02343346e+00,  9.07273685e-01,\n         5.04781361e-01, -6.75878364e-01,  1.70202825e-01,\n        -5.13377488e-01, -1.03081528e+00, -3.38743012e-01,\n         6.98265536e-01,  4.38141928e-02],\n       [ 1.45070992e+00,  7.65780539e-01,  6.58690814e-01,\n        -1.60892655e+00, -2.85158530e-01, -1.06437241e+00,\n        -1.83002880e-01, -6.93276124e-01, -3.77604953e-01,\n         1.06116273e+00,  4.75249929e-01,  1.00711443e+00,\n        -1.60068311e+00,  5.79746966e-02,  9.66704981e-01,\n         1.50629591e+00, -1.54808839e+00, -3.51483636e-01,\n         1.03422667e+00, -1.92278313e-01],\n       [-9.10417674e-01, -1.54999918e+00, -9.48701535e-01,\n        -1.68890167e+00,  5.84604568e-02,  8.96310186e-01,\n        -1.26097476e+00,  2.57729741e-01,  8.45271029e-01,\n        -2.70832685e-03, -1.61069429e+00,  3.86211555e-01,\n        -5.46469448e-02, -1.56504649e-01, -5.46837246e-01,\n         8.67874263e-02,  5.09817908e-01,  2.39064813e+00,\n         1.12332068e-01,  1.51114116e+00],\n       [ 3.57755083e-01, -9.95283276e-02,  1.48547528e-01,\n        -1.22173637e+00,  3.05860271e-01, -1.99206506e+00,\n        -8.62666358e-01,  1.09843093e-01,  1.19398227e+00,\n         1.43062440e+00, -2.36546580e-01,  1.55717320e-01,\n         9.84362470e-01, -1.32949357e+00,  4.04747505e-01,\n        -8.27892867e-01, -1.71825045e-01, -4.59023250e-01,\n         4.35358127e-01,  5.50303674e-01],\n       [ 8.91078677e-01,  3.48198828e-01,  1.71653770e-01,\n         1.85402380e+00, -1.52435907e+00,  1.69560986e+00,\n        -2.89821909e-01,  5.70891586e-01, -3.25659681e-01,\n        -7.02541630e-01,  4.84577193e-01,  1.04212831e+00,\n         4.73007955e-01, -5.42115787e-01,  3.61135006e+00,\n         1.19857367e+00,  9.33342304e-01, -3.52964231e-01,\n        -6.25165788e-01, -2.79839076e-01],\n       [ 1.08140654e+00, -9.90604337e-01, -1.06820383e+00,\n         5.39547533e-01,  3.19196445e-01, -7.70313538e-01,\n        -1.09120358e+00,  1.43789699e+00,  3.57004425e-01,\n        -1.36353586e+00, -1.29362554e+00, -3.61511972e-01,\n         7.32841807e-01,  5.95008802e-01,  1.13167854e+00,\n        -1.49034981e+00,  2.23846690e-01,  1.42591033e+00,\n         1.33280173e+00,  3.58909981e-01],\n       [ 2.34801851e+00,  6.09285116e-01,  1.04274663e+00,\n         4.44479188e-02, -7.80975293e-01, -8.75209201e-01,\n         1.81615215e-01, -2.11502007e-01, -1.76858567e+00,\n        -1.02579358e+00, -3.18403574e-01,  7.27279376e-01,\n        -1.60738862e-02, -7.20642105e-02, -9.86912627e-01,\n         2.31660801e-02,  1.31910103e+00,  1.55575113e-01,\n        -1.50731358e+00, -1.25152279e+00],\n       [ 5.88788877e-01, -2.24315475e-01, -7.45802301e-02,\n        -6.12734175e-01,  5.03412212e-01, -3.00917713e-01,\n        -1.86613222e-01, -8.51223392e-01,  9.21691298e-01,\n        -2.21132792e-01,  6.07880333e-01, -1.19359156e+00,\n         1.73388314e+00,  1.27737404e+00, -1.90979767e+00,\n        -8.01937475e-01,  4.77634391e-01, -1.31972866e+00,\n        -1.31594082e-01,  4.26631786e-01],\n       [-1.84725912e-01,  5.38838704e-01, -6.93329905e-01,\n        -2.24418154e+00,  9.82115312e-01,  9.75814654e-01,\n         2.50363664e+00, -2.20718652e+00,  7.50832109e-01,\n        -1.96868214e+00,  1.75649328e+00,  4.87866834e-01,\n        -9.51928848e-01,  7.80222475e-01, -5.53045008e-01,\n         3.00416100e-01,  2.05960716e-01,  1.74416814e+00,\n         1.81492591e+00, -5.97265373e-01],\n       [ 1.05810562e+00,  3.54840156e-01, -1.41268207e+00,\n        -6.96228380e-01,  2.33614610e+00,  3.57854401e-01,\n         9.99779580e-01, -2.12044312e-01, -5.39941915e-01,\n         2.72645076e-02, -2.66104055e-01, -1.49325293e+00,\n        -1.00332546e+00,  7.07884514e-01, -3.80690689e-01,\n         2.57048820e-02,  2.34923050e-01,  3.13050049e-01,\n         1.14657906e+00, -1.09869582e+00],\n       [ 5.70252724e-01,  7.55027794e-01,  9.85851779e-01,\n        -1.41291760e+00,  2.54819218e-01,  1.71607595e+00,\n        -9.91205192e-02,  4.83494702e-01,  7.80395595e-01,\n        -1.02546984e+00,  1.83382473e+00,  4.99500797e-01,\n         5.19502814e-01, -1.66202738e+00,  7.94544798e-01,\n         5.06410341e-01,  1.62419133e+00, -3.11265214e-01,\n        -9.87658330e-01, -6.82238995e-01],\n       [-5.04978235e-01, -1.11884652e+00,  1.29016002e+00,\n         1.32769786e+00, -1.95791701e-01, -3.92759922e-01,\n        -1.81548191e+00,  6.95961255e-01,  1.65344011e+00,\n        -6.37194717e-01, -1.16784526e-01,  4.34291461e-01,\n         1.72441836e+00,  1.99776222e-01,  1.95429916e-01,\n         1.79318501e-01, -1.42503251e+00, -1.44679065e+00,\n        -8.07995169e-01,  1.01289057e+00],\n       [-3.35357071e-01, -5.29604049e-01, -5.47174604e-01,\n        -1.37656878e-01,  1.70210793e+00, -1.51197386e-01,\n        -7.86297405e-01,  2.52456291e-02,  1.75508361e+00,\n        -5.02824719e-01, -1.18100501e+00, -5.00991270e-01,\n         1.28763736e-01,  6.88240951e-01,  1.00688358e+00,\n        -1.04571727e+00, -9.50845334e-01, -3.23262259e-01,\n         6.84493025e-01, -1.26000790e+00],\n       [-6.07326910e-01, -5.92743729e-01,  9.41748855e-01,\n         5.28260761e-01,  9.03718361e-01,  1.33867797e+00,\n        -3.05650095e-01, -1.18740615e+00, -1.18096362e+00,\n        -1.83810757e+00, -4.58766830e-01, -3.84222615e-01,\n         7.87553407e-01,  1.69142172e-02, -4.90328444e-01,\n        -1.15998726e-01, -1.03897348e+00,  1.02540657e+00,\n        -7.85915563e-01, -1.13993127e+00],\n       [ 8.17881967e-01,  5.74164208e-01, -1.72368538e+00,\n         8.55001635e-01, -7.41592639e-01, -3.74104528e-01,\n         1.87020108e-01,  5.86624883e-01,  4.45479175e-01,\n        -4.98183309e-02, -4.24643329e-01,  4.12220694e-01,\n        -1.18387837e-01,  1.80535446e+00,  5.86409010e-01,\n        -9.23415625e-01, -4.77599951e-01,  4.81921773e-02,\n         1.29943122e+00,  1.41110501e+00]])"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_other = np.random.randn(20, num_features)\n",
    "class_other"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "# Function to perform inference\n",
    "def infer(model, features):\n",
    "    # Ensure the model is in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Convert the numpy array to a PyTorch tensor\n",
    "    features_tensor = torch.tensor(features, dtype=torch.float32)\n",
    "\n",
    "    # Add a batch dimension, as the model expects inputs to be batched\n",
    "    features_tensor = features_tensor.unsqueeze(0)\n",
    "\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(features_tensor)\n",
    "\n",
    "    # Get the predicted class\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    return predicted.item()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "4"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "c1loader = DataLoader(class_one, batch_size=32, shuffle=True)\n",
    "\n",
    "infer(model, class_other[2])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "# Function to perform inference on multiple rows\n",
    "def infer_multiple(model, features):\n",
    "    # Ensure the model is in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Convert the numpy array to a PyTorch tensor\n",
    "    features_tensor = torch.tensor(features, dtype=torch.float32)\n",
    "\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(features_tensor)\n",
    "\n",
    "    # Get the predicted classes in (max value, index of max value)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    return predicted.numpy()  # Convert the tensor back to a numpy array if needed\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.        , 2.11578471],\n       [1.        , 1.68369049],\n       [1.        , 2.64841261],\n       [1.        , 1.42407659],\n       [1.        , 2.59310622],\n       [1.        , 1.33528347],\n       [1.        , 1.30906026],\n       [1.        , 1.38552713],\n       [1.        , 1.39589811],\n       [2.        , 1.22742127]])"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1_predict = infer_multiple(model, class_one)\n",
    "np.c_[c1_predict, class_one[:,0]]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.        ,  0.49671415],\n       [ 1.        ,  1.46564877],\n       [ 0.        ,  0.73846658],\n       ...,\n       [ 3.        , -0.69193084],\n       [ 0.        , -0.11676412],\n       [ 0.        ,  0.96259198]])"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = X[:, 0] > 1\n",
    "y = np.random.randint(0, num_classes, num_samples)\n",
    "\n",
    "y[mask] = 1\n",
    "y[~mask] = np.where(y[~mask] == 1, 0, y[~mask])\n",
    "np.c_[y, X[:,0]]"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
